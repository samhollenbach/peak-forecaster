from itertools import chainimport datetimeimport randomimport tensorflowimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltfrom pickle_jar.pickle_jar import pickle_jarfrom peak_forecaster import load, process, operate, display, networksolar_sites = ['WM3140', 'WM3796', 'WM5603', 'WM5635']def test_standard_operator():    site = 'WM5635'    start = '2018-07-01 00:00:00-07'    end = '2018-08-01 23:45:00-07'    #    # start = '2018-01-03 00:00:00-07'    # end = '2018-02-01 23:45:00-07'    start_date = pd.to_datetime(start).date()    end_date = pd.to_datetime(end).date()    data = load.load_all_data(['WM5635'])    print("\n##### Finished Loading Data ##### \n")    print("NaNs:")    print(data.isna().sum())    print("Stats:")    print(data.describe())    print("Tail:")    print(data.tail())    @pickle_jar(verbose=True, reload=False)    def do_data_split(start_date, end_date, data):        # Get train/test data set split based on given dates        train_data, test_data = process.train_test_split(data,                                                         test_start_date=start_date,                                                         test_end_date=end_date)        return train_data, test_data    @pickle_jar(verbose=True, reload=False)    def do_xy_split(train_data, test_data, y_value='building_baseline'):        # Get x/y features from train and test sets        train_x, train_y = process.extract_features(train_data, y_value=y_value)        test_x, test_y = process.extract_features(test_data, y_value=y_value)        return train_x, train_y, test_x, test_y    # @pickle_jar(verbose=True)    def do_network_training(train_data_x, train_data_y, test_data_x, train_type='baseline'):        print(f"Starting training for: {train_type}")        # Create a network to predict peaks        net = network.Network({'activation': 'relu',                                 'layers': 2,                                 'learning_rate': 0.001,                                 'loss_positive_scalar': 5.0,                                 'nodes': [16, 4],                                 'optimizer': tensorflow.keras.optimizers.RMSprop})        net.build_model(len(train_data_x[0]), len(train_data_y[0]))        net.train_model(train_data_x, train_data_y)        predictions_crs = net.model.predict(test_data_x)        return predictions_crs        # true_peaks = [y[0] for y in test_y]        # dif = [t - p for t, p in zip(true_peaks, predictions)]        #        # plt.scatter(true_peaks, dif)        # plt.show(    train_data, test_data = do_data_split(start_date, end_date, data)    train_x, train_y, test_x, test_y = do_xy_split(train_data, test_data, y_value='building_baseline')    train_x_crs, train_y_crs, test_x_crs, test_y_crs = do_xy_split(train_data,                                                                   test_data, y_value='crs_baseline')    predictions = do_network_training(train_x, train_y, test_x)    predictions_crs = do_network_training(train_x_crs, train_y_crs, test_x_crs, train_type='crs')    # predictions = [[p[0] + c[0]]  for p, c in zip(predictions, predictions_crs)]    # Define standard operation window    operator = operate.StandardOperator(site, start, end)    # Define daily testing window    tstart = datetime.time(10, 0)    tend = datetime.time(23, 0)    # Run standard operation    data = operator.run_standard_operation(tstart, tend, test_data,                                           predictions=predictions,                                           crs_predictions=predictions_crs,                                           threshold_matching=True)    # Calculate operational savings    savings = operator.get_savings(data[['timestamp', 'building_baseline']],                                   data[['timestamp', 'target']])    demand_savings = operator.get_demand_savings(data[['timestamp', 'building_baseline']],                                   data[['timestamp', 'target']])    energy_savings = operator.get_energy_savings(data[['timestamp', 'building_baseline']],                                   data[['timestamp', 'target']])    print(f"Savings: ${savings:.2f}")    print(f"Demand Savings: ${demand_savings:.2f}")    print(f"Energy Savings: ${energy_savings:.2f}")    # Display operational data    display.baseline_plot2(data, savings=(savings, demand_savings, energy_savings))    # print("\n##### Splitting Train/Test Data #####\n")    # x_train_data, y_train_data, x_test_data, y_test_data = \    #     load.train_test_split(    #     data, seed=3)    #    # x_train, y_train, x_test, y_test = process.extract_features(x_train_data,    #                                                             y_train_data,    #                                                             x_test_data,    #                                                             y_test_data)test_standard_operator()