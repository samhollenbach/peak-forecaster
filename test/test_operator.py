from itertools import chainimport datetimeimport randomimport tensorflowimport pandas as pdfrom peak_forecaster import savingsimport osimport numpy as npimport matplotlib.pyplot as pltfrom pickle_jar.pickle_jar import pickle_jarfrom peak_forecaster import load, process, operate, display, networksolar_sites = ['WM3140', 'WM3796', 'WM5603', 'WM5635', 'WFSTC']def test_standard_operator():    site = 'WM3140'    start = '2018-01-01 00:00:00-07'    end = '2018-02-01 00:00:00-07'    #    # start = '2018-01-03 00:00:00-07'    # end = '2018-02-01 23:45:00-07'    data = load.load_all_data([site])    print("\n##### Finished Loading Data ##### \n")    print("NaNs:")    print(data.isna().sum())    print("Stats:")    print(data.describe())    print("Tail:")    print(data.tail())    # @pickle_jar(verbose=True, reload=True)    def do_data_split(start_date, end_date, data):        # Get train/test data set split based on given dates        train_data, test_data = process.train_test_split(data,                                                         test_start_date=start_date,                                                         test_end_date=end_date)        return train_data, test_data    # @pickle_jar(verbose=True, reload=True)    def do_xy_split(train_data, test_data, y_value='building_baseline'):        # Get x/y features from train and test sets        train_x, train_y = process.extract_features(train_data, y_value=y_value)        test_x, test_y = process.extract_features(test_data, y_value=y_value)        return train_x, train_y, test_x, test_y    # @pickle_jar(verbose=True, reload=True)    def do_network_training(train_data_x, train_data_y, test_data_x,                            train_type='baseline'):        print(f"Starting training for: {train_type}")        # Create a network to predict peaks        if train_type == 'baseline':            net = network.Network({'activation': 'relu',                                   'layers': 2,                                   'learning_rate': 0.001,                                   'loss_positive_scalar': 5.0,                                   'nodes': [16, 4],                                   'optimizer':                                       tensorflow.keras.optimizers.RMSprop})        else:            net = network.Network({'activation': 'relu',                                   'layers': 2,                                   'learning_rate': 0.001,                                   'loss_positive_scalar': 1.0,                                   'nodes': [16, 4],                                   'optimizer':                                       tensorflow.keras.optimizers.RMSprop})        net.build_model(len(train_data_x[0]), len(train_data_y[0]))        net.train_model(train_data_x, train_data_y)        predictions_crs = net.model.predict(test_data_x)        return predictions_crs        # true_peaks = [y[0] for y in test_y]        # dif = [t - p for t, p in zip(true_peaks, predictions)]        #        # plt.scatter(true_peaks, dif)        # plt.show(    runs = 0    savings_total = []    savings_demand = []    savings_energy = []    for m in range(5, 11):        for d in ['01', '07', '15', '22']:            data = load.load_all_data([site])            start = f'2018-{m:02d}-{d} 00:00:00-07'            end = f'2018-{m+1:02d}-{d} 23:45:00-07'            print("\nStart: ", start)            print("End: ", end, '\n')            start_date = pd.to_datetime(start).date()            end_date = pd.to_datetime(end).date()            train_data, test_data = do_data_split(start_date, end_date, data)            train_x, train_y, test_x, test_y = do_xy_split(train_data, test_data, y_value='building_baseline')            train_x_crs, train_y_crs, test_x_crs, test_y_crs = do_xy_split(train_data,                                                                           test_data, y_value='crs_baseline')            perfect_forecasting = True            if perfect_forecasting:                # Simulate Perfect Forecasting                predictions = [t for t in test_y]                predictions_crs = [[max(t['crs_baseline'])] for t in test_data]            else:                # Use actual forecasting                predictions = do_network_training(train_x, train_y, test_x)                predictions_crs = do_network_training(train_x_crs, train_y_crs, test_x_crs, train_type='crs')            # Define standard operation window            operator = operate.StandardOperator(site, start, end)            # Define daily testing window            tstart = datetime.time(3, 0)            tend = datetime.time(22, 45)            # Run standard operation            data = operator.run_standard_operation(tstart, tend, test_data,                                                   predictions=predictions,                                                   crs_predictions=predictions_crs,                                                   dynamic_precool=False,                                                   threshold_derating=1.0)            path = f'output/{site}_300_2345'            if not os.path.exists(path):                os.makedirs(path)            data.to_pickle(f'{path}/LT_Setback_EBM_{site}_{start.split(" ")[0]}_{end.split(" ")[0]}.pickle')            s = savings.Savings('pge_e19_2019')            # Calculate operational savings            total_savings = s.get_savings(data[['timestamp', 'building_baseline']],                                           data[['timestamp', 'target']])            demand_savings = s.get_demand_savings(data[['timestamp', 'building_baseline']],                                           data[['timestamp', 'target']])            energy_savings = s.get_energy_savings(data[['timestamp', 'building_baseline']],                                           data[['timestamp', 'target']])            print(f"Savings: ${total_savings:.2f}")            print(f"Demand Savings: ${demand_savings:.2f}")            print(f"Energy Savings: ${energy_savings:.2f}")            savings_total.append(total_savings)            savings_demand.append(demand_savings)            savings_energy.append(energy_savings)            # Display operational data            # display.baseline_plot2(data, savings=(total_savings, demand_savings, energy_savings))            runs += 1    print("All Runs")    print("Total:", savings_total)    print("Demand:", savings_demand)    print("Energy:", savings_energy)    print("Average")    print("Total:", sum(savings_total)/runs)    print("Demand:", sum(savings_demand)/runs)    print("Energy:", sum(savings_energy)/runs)    # print("\n##### Splitting Train/Test Data #####\n")    # x_train_data, y_train_data, x_test_data, y_test_data = \    #     load.train_test_split(    #     data, seed=3)    #    # x_train, y_train, x_test, y_test = process.extract_features(x_train_data,    #                                                             y_train_data,    #                                                             x_test_data,    #                                                             y_test_data)test_standard_operator()